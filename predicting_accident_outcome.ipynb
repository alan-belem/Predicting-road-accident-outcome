{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d89a5f-ed71-4f9b-914c-a1491b5ff0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbbcae9c-e217-4f52-af7e-f40f74b7d15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checando por número de colunas: .csv tem 26 colunas.\n",
      "Checando por número de colunas: .csv tem 25 colunas.\n",
      "Checando por número de colunas: .csv tem 30 colunas.\n",
      "Checando por número de colunas: .csv tem 30 colunas.\n",
      "Checando por número de colunas: .csv tem 30 colunas.\n",
      "Checando por número de colunas: .csv tem 30 colunas.\n",
      "Checando por número de colunas: .csv tem 30 colunas.\n",
      "Checando por número de colunas: .csv tem 30 colunas.\n"
     ]
    }
   ],
   "source": [
    "#Loading Datasets\n",
    "\n",
    "datatran = pd.DataFrame()\n",
    "colunas = pd.DataFrame()\n",
    "\n",
    "dir_path = r\"C:\\Users\\Álan Batista\\Data\\Transito\\*.csv\"\n",
    "res = glob.glob(dir_path)\n",
    "\n",
    "for file in res:\n",
    "    temp = pd.read_csv(file, encoding=\"Latin-1\", delimiter=\";\")\n",
    "    n = len(temp.columns.tolist())\n",
    "    print(f\"Checando por número de colunas: .csv tem {n} colunas.\")    \n",
    "    temp_series = pd.Series(temp.columns.tolist())\n",
    "    colunas = pd.concat([colunas,temp_series])    \n",
    "    datatran = pd.concat([datatran,temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b417bf35-fdca-4f5b-aa05-8d9291803a78",
   "metadata": {},
   "source": [
    "### Checando as colunas que não estão presentes em todos os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913bdf72-4600-44ac-8201-be0fba108ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latitude', 'longitude', 'regional', 'delegacia', 'uop', 'ano']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colunas.columns = ['qtd']\n",
    "colunas_count = colunas['qtd'].value_counts()\n",
    "colunas_count = pd.DataFrame(colunas_count)\n",
    "colunas_count = colunas_count[colunas_count.qtd <8]\n",
    "colunas_count.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba81f2-1dfa-4e91-a12a-6f2f8d1d4e36",
   "metadata": {},
   "source": [
    "### Procurando valores nulos no DataFrame total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae870ab0-4791-4148-9119-e774908fe15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                             0\n",
       "data_inversa                   0\n",
       "dia_semana                     0\n",
       "horario                        0\n",
       "uf                             0\n",
       "br                           882\n",
       "km                           882\n",
       "municipio                      0\n",
       "causa_acidente                 0\n",
       "tipo_acidente                 40\n",
       "classificacao_acidente         1\n",
       "fase_dia                       1\n",
       "sentido_via                    0\n",
       "condicao_metereologica         3\n",
       "tipo_pista                     0\n",
       "tracado_via                    0\n",
       "uso_solo                       0\n",
       "ano                       515480\n",
       "pessoas                        0\n",
       "mortos                         0\n",
       "feridos_leves                  0\n",
       "feridos_graves                 0\n",
       "ilesos                         0\n",
       "ignorados                      0\n",
       "feridos                        0\n",
       "veiculos                       0\n",
       "latitude                  218524\n",
       "longitude                 218524\n",
       "regional                  218530\n",
       "delegacia                 219412\n",
       "uop                       219332\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatran.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5921ed-ee8d-4edc-b88e-440bc1228b66",
   "metadata": {},
   "source": [
    "Quando verificamos as colunas, já havíamos percebido que as variáveis *ano*, *latitude*, *longitude*, *regional*, *delegacia* e *uop* não estão presentes em todos os datasets. Essas variáveis não serão importantes para a criação de um modelo de previsão, então nos livraremos delas.\n",
    "\n",
    "Isso nos deixa algumas variáveis que possuem valores nulos e que precisamos decidir acerca do que fazer: a variável *condicao_meterologica*, com 3 valores nulos; a variavel *fase_dia*, com apenas um valor nulo; a variável *classificacao_acidente*, também com apenas um valor nulo; a variável *tipo_acidente*, com 40 valores nulos; a variável *br* e a variável *km*, com 882 valores nulos cada uma.\n",
    "\n",
    "Começaremos realizando um drop nas colunas que desejamos abandonar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b72569e3-d84b-44f9-92ec-b008be094e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatran.drop(columns=colunas_count.index.tolist(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca32c7-cb5f-4545-8cbd-4f3fbf3a1403",
   "metadata": {},
   "source": [
    "Podemos igualmente nos livrar das colunas br e km, pois não estamos interessados nas localizações específicas e queremos criar um modelo mais geral.\n",
    "\n",
    "Como existem poucas observações nulas nas outras colunas em questão, realizaremos a limpeza das mesmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2eae13-81ef-4d3d-9236-aeaf0ea5c371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a61ab7be-e6c2-44b2-998e-e3dc2b24f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatran.drop(columns=['br','km'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c061eb-f69d-47e1-ab61-e0bfbf5fe5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
